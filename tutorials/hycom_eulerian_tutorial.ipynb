{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Tutorial to get you started with the Eulerian fields of the HYCOM dataset\n",
    "by Shane Elipot (selipot@miami.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook tutorial you will learn how to access the Eulerian data of the dataset **Eulerian and Lagrangian near-surface velocity and sea surface height from one year of the global HYbrid Coordinate Ocean Model (HYCOM)** hosted on the AWS S3 bucket `hycom-global-drifters`. You will also learn how to conduct some simple analysis of the velocity and sea surface height (SSH) data. The data in the bucket are archived as zarr \"files\", or \"store\", or again \"archive\". In the rest of this notebook we will use the name \"store\".\n",
    "\n",
    "To run this notebook you will need a python environment with the common libraries *numpy*, *xarray*, and *matplotlib*. The last part of the tutorial requires some more specialized functions from the *spectrum* and *clouddrift* packages.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computattional imports\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "# plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "\n",
    "# AWS import\n",
    "import s3fs\n",
    "\n",
    "# specialized imports\n",
    "import spectrum \n",
    "from clouddrift.sphere import coriolis_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS S3 bucket file access set up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS set up\n",
    "bucket_name = 'hycom-global-drifters'\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the objects in the Eulerian directory\n",
    "directory = bucket_name + '/eulerian'\n",
    "objects = s3.ls(directory)\n",
    "# Print the objects\n",
    "for obj in objects:\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazily load some data:\n",
    "As you should be able to read in the [README file]() of the bucket, the velocity and Eulerian fields are organized in zarr stores. In addition, the bathymetry (ocean depth) data of the model is contained in its own store. We open the bathymetry store and the velocity and SSH store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first 30 days of data (720 hours) or step 1; feel free to change the step from 1 to 12\n",
    "step = 2\n",
    "zarr_bathy_store_path = bucket_name+'/eulerian/hycom12_bathy.zarr'\n",
    "zarr_velocity_store_path = bucket_name+'/eulerian/hycom12-'+str(step)+'-rechunked-corr.zarr'\n",
    "zarr_ssh_store_path = bucket_name+'/eulerian/hycom12-ssh-'+str(step)+'-rechunked-corr.zarr'\n",
    "\n",
    "# Create Zarr store mapped objects\n",
    "store0 = s3fs.S3Map(root=zarr_bathy_store_path, s3=s3)\n",
    "store1 = s3fs.S3Map(root=zarr_velocity_store_path, s3=s3)\n",
    "store2 = s3fs.S3Map(root=zarr_ssh_store_path, s3=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look a the size of the stores. You will see that the velocity and SSH stores are of a pretty good size, over 327 GB. As a result, we do not necessarily want (or can) download these files locally or hold them in memory. Instead, we will open these files for analysis in a \"lazy\" way with xarray and zarr, that is without downloading the data but only the metadata before deciding what to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The bathymetry store is {np.round(s3.du(zarr_bathy_store_path, total=True)/1024**2,0)} MB.\")\n",
    "print(f\"The velocity store is {np.round(s3.du(zarr_velocity_store_path, total=True)/1024**3,0)} GB.\")\n",
    "print(f\"The SSH store is {np.round(s3.du(zarr_velocity_store_path, total=True)/1024**3,0)} GB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazily open the zarr stores with xarray but force the loading of the bathymetry data\n",
    "ds_bathy = xr.open_zarr(store0, consolidated=\"auto\").load()\n",
    "ds_uv = xr.open_zarr(store1, consolidated=\"auto\")\n",
    "ds_ssh = xr.open_zarr(store2, consolidated=\"auto\")\n",
    "ds_bathy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some of the data:\n",
    "\n",
    "By examining the structure of the bathymetry dataset, you can see that the model data are provided on a non-regular grid with dimensions/coordinates **X** and **Y**. Let's visualize how the Latitude, Longitude, and bathymetry relate to these grids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cyclic colormap for longitude\n",
    "cmap1 = mpl.colormaps[\"hsv\"]\n",
    "cmap2 = mpl.colormaps[\"ocean\"]\n",
    "# get the maximum depth in the model\n",
    "bathymax = ds_bathy[\"bathymetry\"].max().values\n",
    "print(f\"The maximum depth in the domain is {bathymax} m.\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "# Plot Latitude\n",
    "ds_bathy['Latitude'].plot(ax=axes[0])\n",
    "axes[0].set_title('Latitude')\n",
    "# Plot Longitude\n",
    "ds_bathy['Longitude'].plot(ax=axes[1], cmap=cmap1)\n",
    "axes[1].set_title('Longitude')\n",
    "# Plot Bathymetry\n",
    "ds_bathy['bathymetry'].plot(ax=axes[2], cmap=cmap2,vmin=0, vmax=np.round(bathymax))\n",
    "axes[2].set_title('Bathymetry');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some simple visualisation of the velocity and SSH data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the structure of the velocity dataset for the chosen step. You can see that the velocity data in the zarr store are chunked as a single chunk along the **time** dimension and the **X** dimension. As such the data are more amenable to analysis along these dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the structure of the velocity dataset\n",
    "ds_uv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we select the velocity data at a single location (X,Y) of the model, as an example where the model depth is the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the coordinates of the maximum depth and extract the velocity data at that location\n",
    "max_coords = xr.where(ds_bathy['bathymetry'] == bathymax, True, False).argmax(dim=[\"X\",\"Y\"])\n",
    "# Get the indices \n",
    "X1 = max_coords[\"X\"].values\n",
    "Y1 = max_coords[\"Y\"].values\n",
    "print(f\"Selecting point at X={X1}, Y={Y1} with latitude {ds_uv['Latitude'].isel(X=X1,Y=Y1).values} and longitude {ds_uv['Longitude'].isel(X=X1,Y=Y1).values} and depth {ds_bathy['bathymetry'].isel(X=X1,Y=Y1).values} m.\")\n",
    "\n",
    "# We can now extract and load the velocity data at this point as a Datarray; and the ssh data as a dataset\n",
    "z = ds_uv[\"u\"].isel(X=X1-1,Y=Y1)+1j*ds_uv[\"v\"].isel(X=X1-1,Y=Y1).load()\n",
    "ssh = ds_ssh.isel(X=X1-1,Y=Y1).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now visualize the time series of velocity components at the two model depth (0m and 15m), the velocity hodographs, and the SSH time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a gridspec instance with 1 row and 3 columns\n",
    "gs = gridspec.GridSpec(2, 3)\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Create the first subplot of velocity component time series in the first two columns of the grid\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "# velocity time series\n",
    "ax1.plot(z[\"time\"],z.real.isel(Depth=0),label=\"u, 0m\",color=\"red\",linestyle=\"-\")\n",
    "ax1.plot(z[\"time\"],z.imag.isel(Depth=0),label=\"v, 0m\",color=\"red\",linestyle=\"--\")\n",
    "ax1.plot(z[\"time\"],z.real.isel(Depth=1),label=\"u, 15m\",color=\"blue\",linestyle=\"-\")\n",
    "ax1.plot(z[\"time\"],z.imag.isel(Depth=1),label=\"v, 15m\",color=\"blue\",linestyle=\"--\")\n",
    "ax1.hlines(0,z[\"time\"][0],z[\"time\"][-1],linestyle=\":\",color=\"black\")\n",
    "ax1.set_ylabel(\"Velocity (m/s)\")\n",
    "ax1.legend()\n",
    "\n",
    "# Create the second subplot of velocity hodographs in the third column of the grid\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "# velocity hodographs\n",
    "ax2.plot(z.real.isel(Depth=0),z.imag.isel(Depth=0),color=\"red\",label=\"0m\")\n",
    "ax2.plot(z.real.isel(Depth=0),z.imag.isel(Depth=1),color=\"blue\",label=\"15m\")\n",
    "# mean velocity as an arrow\n",
    "ax2.arrow(0, 0, z.real.isel(Depth=0).mean(), z.imag.isel(Depth=0).mean(), \n",
    "    head_width=0.05, head_length=0.1, fc='red', ec='black', linewidth=2, label=\"mean 0m\", zorder=3)\n",
    "ax2.arrow(0, 0, z.real.isel(Depth=1).mean(), z.imag.isel(Depth=1).mean(), \n",
    "    head_width=0.05, head_length=0.1, fc='blue', ec='black', linewidth=2, label=\"mean 15m\", zorder=3)\n",
    "\n",
    "ax2.set_xlabel(\"u (m/s)\")\n",
    "ax2.set_ylabel(\"v (m/s)\")\n",
    "xy_extend = 0.7\n",
    "ax2.set_xlim(-xy_extend,xy_extend)\n",
    "ax2.set_ylim(-xy_extend,xy_extend)\n",
    "ax2.vlines(0,-xy_extend,xy_extend,linestyle=\":\",color=\"black\")\n",
    "ax2.hlines(0,-xy_extend,xy_extend,linestyle=\":\",color=\"black\")\n",
    "ax2.legend()\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, :2])\n",
    "# SSH time series\n",
    "ax3.plot(ssh[\"time\"],ssh[\"steric_ssh\"],label=\"Steric SSH\",color=\"black\")\n",
    "ax3.plot(ssh[\"time\"],ssh[\"ssh\"]-ssh[\"steric_ssh\"],label=\"Non-steric SSH\",color=\"gray\")\n",
    "ax3.hlines(0,ssh[\"time\"][0],ssh[\"time\"][-1],linestyle=\":\",color=\"black\")\n",
    "ax3.set_ylabel(\"Height (m)\")\n",
    "ax3.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some simple spectral analysis:\n",
    "\n",
    "In this last part of the tutorial, we conduct some simple spectral analysis of the velocity and SSH data. We start by defining a function to calculate a multitaper spectral estimate. We then apply this function to the time series of velocity and SSH to obtain their spectra. If you would like to learn a bit more about estimating spectra with pytho, you can head out to my [dedicated repository](https://github.com/selipot/congenial-spectrum) for that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to get a multitaper spectral estimate\n",
    "def pmtm(x,dt=1,nw=3,method=\"unity\"):\n",
    "    \"\"\"\n",
    "    spectral multitaper estimate\n",
    "    Args:\n",
    "        x : vector input\n",
    "        dt : sampling rate, default = 1\n",
    "        nw : time-bandwidth product, default = 3\n",
    "        k : number of tapers, default 2*nw-1\n",
    "        method : multitaper method:  eigen, unity (default as it conserve the variance), or adapt\n",
    "        \n",
    "    Returns:\n",
    "        f : Fourier frequencies\n",
    "        s : spectral estimate\n",
    "    \"\"\"\n",
    "    k = int(2*nw-1)\n",
    "    f = np.fft.fftfreq(x.shape[0],dt) # define frequency scale/abscissa, dt is in units of days\n",
    "    psi, eigs = spectrum.mtm.dpss(x.shape[0],NW=nw,k=k)\n",
    "    if method==\"adapt\":\n",
    "        Zk, weights, eigenvalues = spectrum.mtm.pmtm(x-np.mean(x),k,NFFT=np.size(x),v=psi,e=eigs,method=method)\n",
    "        S = np.mean(np.abs(Zk*weights.T)**2, axis=0)*dt  \n",
    "    else:\n",
    "        Zk, weights, eigenvalues = spectrum.mtm.pmtm(x-np.mean(x),k,NFFT=np.size(x),v=psi,e=eigs,method=method)\n",
    "        S = np.mean(np.abs(Zk*weights)**2, axis=0)*dt  \n",
    "\n",
    "    return f,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the rotary spectral density of the velocity and SSH time series\n",
    "dt = 1/24\n",
    "fz1, Sz1 = pmtm(x=z.isel(Depth=0).to_numpy(),dt=dt)\n",
    "fz2, Sz2 = pmtm(x=z.isel(Depth=1).to_numpy(),dt=dt)\n",
    "fz3, Sz3 = pmtm(x=ssh[\"steric_ssh\"].to_numpy(),dt=dt)\n",
    "fz4, Sz4 = pmtm(x=ssh[\"ssh\"].to_numpy()-ssh[\"steric_ssh\"].to_numpy(),dt=dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coriolis frequency in cycles per day which is the opposite of the Coriolis parameter\n",
    "finert = -86400*(1/(2*np.pi))*coriolis_frequency(ds_uv['Latitude'].isel(X=X1,Y=Y1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the spectra\n",
    "# The velocity spectra are rotary spectra, meaning that positive and negative frequencies are meaningful and physically interpretable. \n",
    "# For the SSH, only positive frequencies are meaningful and thus we limited the x-axis to positive frequencies but multiply the spectra by two to retain variance.\n",
    "qpos = np.where(fz3>=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(13, 6))\n",
    "h1, = ax.plot(np.fft.fftshift(fz1),np.fft.fftshift(np.log10(Sz1)),scaley=True,linewidth=1,color=\"red\",label=\"0m\")\n",
    "h2, = ax.plot(np.fft.fftshift(fz2),np.fft.fftshift(np.log10(Sz2)),scaley=True,linewidth=1,color=\"blue\",label=\"15m\")\n",
    "h3, = ax.plot(fz3[qpos],np.log10(2*Sz3[qpos]),scaley=True,linewidth=1,color=\"black\",label=\"Steric SSH\")\n",
    "h4, = ax.plot(fz4[qpos],np.log10(2*Sz4[qpos]),scaley=True,linewidth=1,color=\"gray\",label=\"Non-steric SSH\")\n",
    "\n",
    "h5 = ax.vlines(finert,ymin=-8,ymax=0,linewidth=1,color='g',linestyle='--',label='Inertial frequency')\n",
    "h6 = ax.vlines(-finert,ymin=-8,ymax=0,linewidth=1,color='c',linestyle='--',label='Coriolis frequency')\n",
    "ax.legend()#,[\"0m\",\"15m\",\"Steric SSH\",\"Non-steric SSH\"])\n",
    "ax.set_ylabel('PSD (m$^2$ s$^{-2}$ cpd$^{-1}$ or m$^2$ cpd$^{-1}$)')\n",
    "ax.set_xlabel('Frequency (cycle per day)')\n",
    "ax.set_xlim([-12,12])\n",
    "ax.set_xticks(np.arange(-12,12,2))\n",
    "\n",
    "ax.set_ylim([-8,0])\n",
    "ax.grid(axis='x')    \n",
    "ax.title.set_text('Multitaper Power Spectral Density of velocity and SSH')\n",
    "ax.set_xticks(ticks=np.arange(-12,13,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the figure above, both the velocity and SSH signals exhibit large tidal peaks near 1,2,3 etc cycles per day. At the inertial and Coriolis frequencies, only the velocity signals seem to exhibit a significant peak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hycom-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
